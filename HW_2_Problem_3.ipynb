{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW 2 Problem 3.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "sk-rP_tGOTi-"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DCunoUCF/cap4630/blob/master/HW_2_Problem_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMzuvWFTzHnC",
        "colab_type": "text"
      },
      "source": [
        "#David Cuno\n",
        "#Professor Wocjan\n",
        "#CAP 4630\n",
        "#11/12/19"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4obk-lyzGgN",
        "colab_type": "text"
      },
      "source": [
        "#Problem 3\n",
        "\n",
        "In this problem you have to work with the CIFAR10 data set. Check out the notebook cifar10_data_set to see how to load it.\n",
        "\n",
        "Give three convolutional models that\n",
        "\n",
        "    first model underfits\n",
        "    second model overfits\n",
        "    third model is pretty good\n",
        "\n",
        "Make sure that you plot the curves depicting the training/validation accuracy/loss."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4N8Q3nDIef8Z",
        "colab_type": "text"
      },
      "source": [
        "# UNDERFIT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80QbvLCsvOSR",
        "colab_type": "code",
        "outputId": "de629edf-4bf5-48d9-e365-efd56c81a448",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import keras\n",
        "# data set\n",
        "from keras.datasets import cifar10\n",
        "# layers\n",
        "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
        "from keras.layers import AveragePooling2D, Input, Flatten\n",
        "# optimizers\n",
        "from keras.optimizers import Adam\n",
        "# callbacks\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "# data augmentation\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "# regularizers\n",
        "from keras.regularizers import l2\n",
        "# backend\n",
        "from keras import backend as K\n",
        "# model\n",
        "from keras import Model\n",
        "# utils\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "# numpy\n",
        "import numpy as np\n",
        "# os\n",
        "import os\n",
        "# IPython display\n",
        "from IPython.display import SVG\n",
        "# matplotlib\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Training parameters\n",
        "batch_size = 32\n",
        "epochs = 20 # default was 200\n",
        "data_augmentation = False\n",
        "num_classes = 10\n",
        "\n",
        "# Subtracting pixel mean improves accuracy\n",
        "subtract_pixel_mean = True\n",
        "\n",
        "# Model parameter\n",
        "n = 3\n",
        "\n",
        "# Model version\n",
        "version = 1\n",
        "\n",
        "# Computed depth from supplied model parameter n\n",
        "if version == 1:\n",
        "    depth = n * 6 + 2\n",
        "elif version == 2:\n",
        "    depth = n * 9 + 2\n",
        "\n",
        "# Model name, depth and version\n",
        "model_type = 'ResNet%dv%d' % (depth, version)\n",
        "\n",
        "# Load the CIFAR10 data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normalize data\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "# Convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# Input dimensions\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "# Number of non-test examples\n",
        "num_train = x_train.shape[0] \n",
        "\n",
        "# If subtract pixel mean is enabled\n",
        "if subtract_pixel_mean:\n",
        "  x_train_mean = np.mean(x_train, axis=0)\n",
        "  x_train -= x_train_mean\n",
        "  x_test -= x_train_mean\n",
        "\n",
        "print('shapes')\n",
        "print()\n",
        "print('x_train:', x_train.shape)\n",
        "print('y_train:', y_train.shape)\n",
        "print('x_test :', x_test.shape)\n",
        "print('y_test :', y_test.shape)\n",
        "\n",
        "def lr_schedule(epoch):\n",
        "  \"\"\"Learning Rate Schedule\n",
        "  \n",
        "  Learning rate is scheduled to be reduced after 100, 150, 200, 225 epochs.\n",
        "  Called automatically every epoch as part of callbacks during training.\n",
        "  \n",
        "  # Argument\n",
        "    epoch (int): The number of epochs\n",
        "    \n",
        "  # Returns \n",
        "    lr (float32): learning rate\n",
        "  \"\"\"\n",
        "  \n",
        "  lr = 1e-3\n",
        "  \n",
        "  if epoch > 180:\n",
        "      lr *= 0.5e-3\n",
        "  elif epoch > 160:\n",
        "      lr *= 1e-3\n",
        "  elif epoch > 120:\n",
        "      lr *= 1e-2\n",
        "  elif epoch > 80:\n",
        "      lr *= 1e-1\n",
        "  #print('Learning rate: ', lr)\n",
        "  return lr\n",
        "  \n",
        "plt.title('Learning rate schedule')\n",
        "plt.plot(range(epochs), [lr_schedule(epoch) for epoch in range(epochs)])\n",
        "plt.ylabel('learning rate')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()\n",
        "\n",
        "def resnet_layer(inputs, \n",
        "                 num_filters=8, # default was 16 \n",
        "                 kernel_size=3, \n",
        "                 strides=1,\n",
        "                 activation='relu', \n",
        "                 batch_normalization=True, \n",
        "                 conv_first=True):\n",
        "  \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
        "\n",
        "    # Arguments\n",
        "        inputs (tensor): input tensor from input image or previous layer\n",
        "        num_filters (int): Conv2D number of filters\n",
        "        kernel_size (int): Conv2D square kernel dimensions\n",
        "        strides (int): Conv2D square stride dimensions\n",
        "        activation (string): activation name\n",
        "        batch_normalization (bool): whether to include batch normalization\n",
        "        conv_first (bool): conv-bn-activation (True) or\n",
        "            bn-activation-conv (False)\n",
        "\n",
        "    # Returns\n",
        "        x (tensor): tensor as input to the next layer\n",
        "    \"\"\"\n",
        "  conv = Conv2D(num_filters, \n",
        "                kernel_size=kernel_size, \n",
        "                strides=strides, \n",
        "                padding='same', \n",
        "                kernel_initializer='he_normal', \n",
        "                kernel_regularizer=l2(1e-4))  \n",
        "  \n",
        "  x = inputs\n",
        "  if conv_first:\n",
        "    # apply conv layer first\n",
        "    x = conv(x)\n",
        "    if batch_normalization:\n",
        "      x = BatchNormalization()(x)\n",
        "    if activation is not None:\n",
        "      x = Activation(activation)(x)\n",
        "  else:\n",
        "    if batch_normalization:\n",
        "      x = BatchNormalization()(x)\n",
        "    if activation is not None:\n",
        "      x = Activation(activation)(x)\n",
        "    # apply conv layer last\n",
        "    x = conv(x)\n",
        "      \n",
        "  return x  \n",
        "\n",
        "def resnet_v1(input_shape, depth, num_classes):\n",
        "  \"\"\"ResNet Version 1 Model builder [a]\n",
        "\n",
        "  Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
        "  Last ReLU is after the shortcut connection.\n",
        "  At the beginning of each stage, the feature map size is halved (downsampled)\n",
        "  by a convolutional layer with strides=2, while the number of filters is\n",
        "  doubled. Within each stage, the layers use the same type of filters \n",
        "  (in terms of size, stride, padding) and the same number of filters.\n",
        "  Features maps sizes:\n",
        "  stage 0: 32x32, 16\n",
        "  stage 1: 16x16, 32\n",
        "  stage 2:  8x8,  64\n",
        "    \n",
        "  # Arguments\n",
        "      input_shape (tensor): shape of input image tensor\n",
        "      depth (int): number of core convolutional layers\n",
        "      num_classes (int): number of classes (CIFAR10 has 10)\n",
        "\n",
        "  # Returns\n",
        "      model (Model): Keras model instance\n",
        "  \"\"\"\n",
        "  \n",
        "  if (depth - 2) % 6 != 0:\n",
        "    raise ValueError('depth should be 6n+2 (eg 20, 32, 44)')\n",
        "  # Start model definition\n",
        "  num_filters = 8 # default was 16\n",
        "  num_res_blocks = int((depth - 2) / 6)\n",
        "  \n",
        "  inputs = Input(shape=input_shape)\n",
        "  x = resnet_layer(inputs=inputs)\n",
        "  \n",
        "  # Instantiate the stack of residual inputs\n",
        "  for stack in range(3):\n",
        "    for res_block in range(num_res_blocks):\n",
        "      \n",
        "      strides = 1\n",
        "      if stack > 0 and res_block == 0: \n",
        "        # first layer but not first stack\n",
        "        # downsample\n",
        "        strides = 2 \n",
        "        \n",
        "      y = resnet_layer(inputs=x, \n",
        "                       num_filters=num_filters,\n",
        "                       strides=strides)\n",
        "      y = resnet_layer(inputs=y,\n",
        "                       num_filters=num_filters,\n",
        "                       activation=None)\n",
        "      \n",
        "      if stack > 0 and res_block == 0: \n",
        "        # first layer but not first stack\n",
        "        # linear projection residual shortcut connection to match\n",
        "        # changed dims\n",
        "        x = resnet_layer(inputs=x,\n",
        "                         num_filters=num_filters,\n",
        "                         kernel_size=1,\n",
        "                         strides=strides,\n",
        "                         activation=None,\n",
        "                         batch_normalization=False)\n",
        "      x = keras.layers.add([x,y])\n",
        "      x = Activation('relu')(x)\n",
        "    num_filters *=2\n",
        "    \n",
        "  # Add classifier on top\n",
        "  # v1 does not use BN after last shortcut connection-ReLU\n",
        "  x = AveragePooling2D(pool_size=8)(x)\n",
        "  y = Flatten()(x)\n",
        "  outputs = Dense(num_classes,\n",
        "                  activation='softmax',\n",
        "                  kernel_initializer='he_normal')(y)\n",
        "  # Instantiate model\n",
        "  model = Model(inputs=inputs, outputs=outputs)\n",
        "  return model\n",
        "\n",
        "model = resnet_v1(input_shape, 20, 10)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(lr=lr_schedule(0)),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Prepare model model saving directory.\n",
        "# save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "# model_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type\n",
        "# if not os.path.isdir(save_dir):\n",
        "#     os.makedirs(save_dir)\n",
        "# filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# Prepare callbacks for model saving and for learning rate adjustment.\n",
        "# checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "#                              monitor='val_acc',\n",
        "#                              verbose=1,\n",
        "#                              save_best_only=True)\n",
        "\n",
        "# lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "# lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "#                                cooldown=0,\n",
        "#                                patience=5,\n",
        "#                                min_lr=0.5e-6)\n",
        "\n",
        "# callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
        "\n",
        "# Run training, with or without data augmentation.\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    history = model.fit(x_train, y_train,\n",
        "                        batch_size=batch_size,\n",
        "                        epochs=epochs,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        shuffle=True,\n",
        "                        verbose=0,\n",
        "                        callbacks=callbacks)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        # set input mean to 0 over the dataset\n",
        "        featurewise_center=False,\n",
        "        # set each sample mean to 0\n",
        "        samplewise_center=False,\n",
        "        # divide inputs by std of dataset\n",
        "        featurewise_std_normalization=False,\n",
        "        # divide each input by its std\n",
        "        samplewise_std_normalization=False,\n",
        "        # apply ZCA whitening\n",
        "        zca_whitening=False,\n",
        "        # epsilon for ZCA whitening\n",
        "        zca_epsilon=1e-06,\n",
        "        # randomly rotate images in the range (deg 0 to 180)\n",
        "        rotation_range=0,\n",
        "        # randomly shift images horizontally\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically\n",
        "        height_shift_range=0.1,\n",
        "        # set range for random shear\n",
        "        shear_range=0.,\n",
        "        # set range for random zoom\n",
        "        zoom_range=0.,\n",
        "        # set range for random channel shifts\n",
        "        channel_shift_range=0.,\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        # value used for fill_mode = \"constant\"\n",
        "        cval=0.,\n",
        "        # randomly flip images\n",
        "        horizontal_flip=True,\n",
        "        # randomly flip images\n",
        "        vertical_flip=False,\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "    # Compute quantities required for featurewise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    history = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                                  validation_data=(x_test, y_test),\n",
        "                                  shuffle=True,\n",
        "                                  epochs=epochs, \n",
        "                                  steps_per_epoch=num_train // batch_size,\n",
        "                                  verbose=0, \n",
        "                                  callbacks=callbacks)\n",
        "    \n",
        "# Score trained model.\n",
        "# test\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])\n",
        "\n",
        "# Score trained model.\n",
        "# train\n",
        "scores = model.evaluate(x_train, y_train, verbose=1)\n",
        "print('Train loss:', scores[0])\n",
        "print('Train accuracy:', scores[1])\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# training and validation accuracy\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='test acc')\n",
        "plt.title('training and test accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "# training and validation loss\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='test loss')\n",
        "plt.title('training and test loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "start_epoch = 0 # default was 60\n",
        "\n",
        "# # training and validation accuracy\n",
        "\n",
        "# plt.plot(epochs[start_epoch:], acc[start_epoch:], 'bo', label='training acc')\n",
        "# plt.plot(epochs[start_epoch:], val_acc[start_epoch:], 'r', label='validation acc')\n",
        "# plt.title('training and validation accuracy')\n",
        "# plt.legend()\n",
        "\n",
        "# plt.figure()\n",
        "\n",
        "# # training and validation loss\n",
        "\n",
        "# plt.plot(epochs[start_epoch:], loss[start_epoch:], 'bo', label='training loss')\n",
        "# plt.plot(epochs[start_epoch:], val_loss[start_epoch:], 'r', label='validation loss')\n",
        "# plt.title('training and validation loss')\n",
        "# plt.legend()\n",
        "\n",
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shapes\n",
            "\n",
            "x_train: (50000, 32, 32, 3)\n",
            "y_train: (50000, 10)\n",
            "x_test : (10000, 32, 32, 3)\n",
            "y_test : (10000, 10)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEWCAYAAACwtjr+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Not using data augmentation.\n",
            "\n",
            "Epoch 00001: val_acc improved from 0.30520 to 0.45310, saving model to /content/saved_models/cifar10_ResNet20v1_model.001.h5\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.45310 to 0.60490, saving model to /content/saved_models/cifar10_ResNet20v1_model.002.h5\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.60490 to 0.64590, saving model to /content/saved_models/cifar10_ResNet20v1_model.003.h5\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.64590 to 0.67030, saving model to /content/saved_models/cifar10_ResNet20v1_model.004.h5\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.67030\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.67030 to 0.69140, saving model to /content/saved_models/cifar10_ResNet20v1_model.006.h5\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.69140 to 0.69550, saving model to /content/saved_models/cifar10_ResNet20v1_model.007.h5\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.69550 to 0.71400, saving model to /content/saved_models/cifar10_ResNet20v1_model.008.h5\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.71400\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.71400\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.71400 to 0.72660, saving model to /content/saved_models/cifar10_ResNet20v1_model.011.h5\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.72660\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.72660\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.72660 to 0.74610, saving model to /content/saved_models/cifar10_ResNet20v1_model.014.h5\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.74610\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.74610\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.74610\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.74610\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.74610\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.74610\n",
            "10000/10000 [==============================] - 3s 281us/step\n",
            "Test loss: 1.1345192684173584\n",
            "Test accuracy: 0.7128\n",
            "50000/50000 [==============================] - 14s 283us/step\n",
            "Train loss: 0.6967203836345672\n",
            "Train accuracy: 0.80092\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkyAsoRtjTIKwhG6MMQnCEroxxiSI/w9KIJk0JjencwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "km6XWlTghyG9",
        "colab_type": "text"
      },
      "source": [
        "# OVERFIT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzBJXfwnhznR",
        "colab_type": "code",
        "outputId": "aeee51cf-b016-4664-e4ff-074985927024",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        }
      },
      "source": [
        "import keras\n",
        "# data set\n",
        "from keras.datasets import cifar10\n",
        "# layers\n",
        "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
        "from keras.layers import AveragePooling2D, Input, Flatten\n",
        "# optimizers\n",
        "from keras.optimizers import Adam\n",
        "# callbacks\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "# data augmentation\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "# regularizers\n",
        "from keras.regularizers import l2\n",
        "# backend\n",
        "from keras import backend as K\n",
        "# model\n",
        "from keras import Model\n",
        "# utils\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "# numpy\n",
        "import numpy as np\n",
        "# os\n",
        "import os\n",
        "# IPython display\n",
        "from IPython.display import SVG\n",
        "# matplotlib\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Training parameters\n",
        "batch_size = 32\n",
        "epochs = 10 # default was 200 #################################\n",
        "data_augmentation = True\n",
        "num_classes = 10\n",
        "\n",
        "# Subtracting pixel mean improves accuracy\n",
        "subtract_pixel_mean = True\n",
        "\n",
        "# Model parameter\n",
        "n = 3\n",
        "\n",
        "# Model version\n",
        "version = 1\n",
        "\n",
        "# Computed depth from supplied model parameter n\n",
        "if version == 1:\n",
        "    depth = n * 6 + 2\n",
        "elif version == 2:\n",
        "    depth = n * 9 + 2\n",
        "\n",
        "# Model name, depth and version\n",
        "model_type = 'ResNet%dv%d' % (depth, version)\n",
        "\n",
        "# Load the CIFAR10 data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normalize data\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "# Convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# Input dimensions\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "# Number of non-test examples\n",
        "num_train = x_train.shape[0] \n",
        "\n",
        "# If subtract pixel mean is enabled\n",
        "if subtract_pixel_mean:\n",
        "  x_train_mean = np.mean(x_train, axis=0)\n",
        "  x_train -= x_train_mean\n",
        "  x_test -= x_train_mean\n",
        "\n",
        "# print('shapes')\n",
        "# print()\n",
        "# print('x_train:', x_train.shape)\n",
        "# print('y_train:', y_train.shape)\n",
        "# print('x_test :', x_test.shape)\n",
        "# print('y_test :', y_test.shape)\n",
        "\n",
        "def lr_schedule(epoch):\n",
        "  \"\"\"Learning Rate Schedule\n",
        "  \n",
        "  Learning rate is scheduled to be reduced after 100, 150, 200, 225 epochs.\n",
        "  Called automatically every epoch as part of callbacks during training.\n",
        "  \n",
        "  # Argument\n",
        "    epoch (int): The number of epochs\n",
        "    \n",
        "  # Returns \n",
        "    lr (float32): learning rate\n",
        "  \"\"\"\n",
        "  \n",
        "  lr = 1e-1 # default was 1e-3\n",
        "  \n",
        "  if epoch > 180:\n",
        "      lr *= 0.5e-3\n",
        "  elif epoch > 160:\n",
        "      lr *= 1e-3\n",
        "  elif epoch > 120:\n",
        "      lr *= 1e-2\n",
        "  elif epoch > 80:\n",
        "      lr *= 1e-1\n",
        "  #print('Learning rate: ', lr)\n",
        "  return lr\n",
        "  \n",
        "# plt.title('Learning rate schedule')\n",
        "# plt.plot(range(epochs), [lr_schedule(epoch) for epoch in range(epochs)])\n",
        "# plt.ylabel('learning rate')\n",
        "# plt.xlabel('epoch')\n",
        "# plt.show()\n",
        "\n",
        "def resnet_layer(inputs, \n",
        "                 num_filters=16, # default was 16 ##########################\n",
        "                 kernel_size=3, \n",
        "                 strides=1,\n",
        "                 activation='relu', \n",
        "                 batch_normalization=True, \n",
        "                 conv_first=True):\n",
        "  \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
        "\n",
        "    # Arguments\n",
        "        inputs (tensor): input tensor from input image or previous layer\n",
        "        num_filters (int): Conv2D number of filters\n",
        "        kernel_size (int): Conv2D square kernel dimensions\n",
        "        strides (int): Conv2D square stride dimensions\n",
        "        activation (string): activation name\n",
        "        batch_normalization (bool): whether to include batch normalization\n",
        "        conv_first (bool): conv-bn-activation (True) or\n",
        "            bn-activation-conv (False)\n",
        "\n",
        "    # Returns\n",
        "        x (tensor): tensor as input to the next layer\n",
        "    \"\"\"\n",
        "  conv = Conv2D(num_filters, \n",
        "                kernel_size=kernel_size, \n",
        "                strides=strides, \n",
        "                padding='same', \n",
        "                kernel_initializer='he_normal', \n",
        "                kernel_regularizer=l2(1e-4))  \n",
        "  \n",
        "  x = inputs\n",
        "  if conv_first:\n",
        "    # apply conv layer first\n",
        "    x = conv(x)\n",
        "    if batch_normalization:\n",
        "      x = BatchNormalization()(x)\n",
        "    if activation is not None:\n",
        "      x = Activation(activation)(x)\n",
        "  else:\n",
        "    if batch_normalization:\n",
        "      x = BatchNormalization()(x)\n",
        "    if activation is not None:\n",
        "      x = Activation(activation)(x)\n",
        "    # apply conv layer last\n",
        "    x = conv(x)\n",
        "      \n",
        "  return x  \n",
        "\n",
        "def resnet_v1(input_shape, depth, num_classes):\n",
        "  \"\"\"ResNet Version 1 Model builder [a]\n",
        "\n",
        "  Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
        "  Last ReLU is after the shortcut connection.\n",
        "  At the beginning of each stage, the feature map size is halved (downsampled)\n",
        "  by a convolutional layer with strides=2, while the number of filters is\n",
        "  doubled. Within each stage, the layers use the same type of filters \n",
        "  (in terms of size, stride, padding) and the same number of filters.\n",
        "  Features maps sizes:\n",
        "  stage 0: 32x32, 16\n",
        "  stage 1: 16x16, 32\n",
        "  stage 2:  8x8,  64\n",
        "    \n",
        "  # Arguments\n",
        "      input_shape (tensor): shape of input image tensor\n",
        "      depth (int): number of core convolutional layers\n",
        "      num_classes (int): number of classes (CIFAR10 has 10)\n",
        "\n",
        "  # Returns\n",
        "      model (Model): Keras model instance\n",
        "  \"\"\"\n",
        "  \n",
        "  if (depth - 2) % 6 != 0:\n",
        "    raise ValueError('depth should be 6n+2 (eg 20, 32, 44)')\n",
        "  # Start model definition\n",
        "  num_filters = 16 # default was 16 ####################################\n",
        "  num_res_blocks = int((depth - 2) / 6)\n",
        "  \n",
        "  inputs = Input(shape=input_shape)\n",
        "  x = resnet_layer(inputs=inputs)\n",
        "  \n",
        "  # Instantiate the stack of residual inputs\n",
        "  for stack in range(3):\n",
        "    for res_block in range(num_res_blocks):\n",
        "      \n",
        "      strides = 1\n",
        "      if stack > 0 and res_block == 0: \n",
        "        # first layer but not first stack\n",
        "        # downsample\n",
        "        strides = 2 \n",
        "        \n",
        "      y = resnet_layer(inputs=x, \n",
        "                       num_filters=num_filters,\n",
        "                       strides=strides)\n",
        "      y = resnet_layer(inputs=y,\n",
        "                       num_filters=num_filters,\n",
        "                       activation=None)\n",
        "      \n",
        "      if stack > 0 and res_block == 0: \n",
        "        # first layer but not first stack\n",
        "        # linear projection residual shortcut connection to match\n",
        "        # changed dims\n",
        "        x = resnet_layer(inputs=x,\n",
        "                         num_filters=num_filters,\n",
        "                         kernel_size=1,\n",
        "                         strides=strides,\n",
        "                         activation=None,\n",
        "                         batch_normalization=False)\n",
        "      x = keras.layers.add([x,y])\n",
        "      x = Activation('relu')(x)\n",
        "    num_filters *=2\n",
        "    \n",
        "  # Add classifier on top\n",
        "  # v1 does not use BN after last shortcut connection-ReLU\n",
        "  x = AveragePooling2D(pool_size=8)(x) # default was 8\n",
        "  y = Flatten()(x)\n",
        "  outputs = Dense(num_classes,\n",
        "                  activation='softmax',\n",
        "                  kernel_initializer='he_normal')(y)\n",
        "  # Instantiate model\n",
        "  model = Model(inputs=inputs, outputs=outputs)\n",
        "  return model\n",
        "\n",
        "model = resnet_v1(input_shape, 32, 10) # default was (..., 20, 10) ##################\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(lr=lr_schedule(0)),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Run training, with or without data augmentation.\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    history = model.fit(x_train, y_train,\n",
        "                        batch_size=batch_size,\n",
        "                        epochs=epochs,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        shuffle=True,\n",
        "                        verbose=0,\n",
        "                        callbacks=callbacks)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        # set input mean to 0 over the dataset\n",
        "        featurewise_center=False,\n",
        "        # set each sample mean to 0\n",
        "        samplewise_center=False,\n",
        "        # divide inputs by std of dataset\n",
        "        featurewise_std_normalization=False,\n",
        "        # divide each input by its std\n",
        "        samplewise_std_normalization=False,\n",
        "        # apply ZCA whitening\n",
        "        zca_whitening=False,\n",
        "        # epsilon for ZCA whitening\n",
        "        zca_epsilon=1e-06,\n",
        "        # randomly rotate images in the range (deg 0 to 180)\n",
        "        rotation_range=0,\n",
        "        # randomly shift images horizontally\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically\n",
        "        height_shift_range=0.1,\n",
        "        # set range for random shear\n",
        "        shear_range=0.,\n",
        "        # set range for random zoom\n",
        "        zoom_range=0.,\n",
        "        # set range for random channel shifts\n",
        "        channel_shift_range=0.,\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        # value used for fill_mode = \"constant\"\n",
        "        cval=0.,\n",
        "        # randomly flip images\n",
        "        horizontal_flip=True,\n",
        "        # randomly flip images\n",
        "        vertical_flip=False,\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "    # Compute quantities required for featurewise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    history = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                                  validation_data=(x_test, y_test),\n",
        "                                  shuffle=True,\n",
        "                                  epochs=epochs, \n",
        "                                  steps_per_epoch=num_train // batch_size,\n",
        "                                  verbose=0, \n",
        "                                  callbacks=callbacks)\n",
        "    \n",
        "# Score trained model.\n",
        "# test\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])\n",
        "\n",
        "# Score trained model.\n",
        "# train\n",
        "scores = model.evaluate(x_train, y_train, verbose=1)\n",
        "print('Train loss:', scores[0])\n",
        "print('Train accuracy:', scores[1])\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# training and validation accuracy\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='test acc')\n",
        "plt.title('training and test accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "# training and validation loss\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='test loss')\n",
        "plt.title('training and test loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.77880\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.77880\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.77880\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.77880\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.77880\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.77880\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcHQE062h0Mn",
        "colab_type": "text"
      },
      "source": [
        "# PRETTY GOOD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkRJHA-Lh23O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}